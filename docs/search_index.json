[["inference.html", "Chapter 2 Inference algorithms", " Chapter 2 Inference algorithms This chapter describes how to run the various inference algorithms implemented in the ilike package, with a section devoted to each algorithm. Preceding these sections, section 2.1 describes the arguments that are common to all of the inference algorithms which allow, for example, the user to specify parameters, the random number seed, etc. When developing ilike, much of the focus has been on Bayesian computation, although the software can be used to simulate from and perform optimisation on any distribution. In this chapter we provide a descriptions of the algorithms implemented in the software. To aid these descriptions we begin by setting out some notation. Most algorithms are used to estimate properties of a target distribution \\(\\pi\\) on a space \\(\\Theta\\). In most cases, \\(\\pi\\) is only known up to a normalising constant: we use \\(\\tilde{\\pi}\\) to denote its unnormalised form with \\(Z\\) as the corresponding normalising constant, so that \\[ \\pi(\\theta) = \\tilde{\\pi}(\\theta)/Z. \\] In the case of Bayesian computation, the target distribution is the posterior distribution of parameters \\(\\theta \\in \\Theta\\) given data \\(y\\). In this case we have \\[ \\tilde{\\pi}(\\theta) = p(\\theta)f(y|\\theta), \\] where \\(f(y|\\theta)\\) is a data model for \\(y\\) given \\(\\theta\\) and \\(p(\\theta)\\) is a prior distribution. When \\(f(y|\\theta)\\) is thought of as a function of \\(\\theta\\) with \\(y\\) fixed, it is known as a likelihood. The normalising constant \\(Z\\) is the marginal likelihood of the data \\(y\\): \\[ Z = \\int_{\\vartheta} p(\\vartheta) f(y \\mid \\vartheta) d \\vartheta. \\] Quantities of interest in Bayesian computation are almost always integrals. For example: the posterior expectation \\[ \\mathbb{E}_{\\pi}\\left[ \\theta \\right] = \\int_{\\theta} \\theta \\pi(\\theta) d\\theta, \\] or the posterior variance \\[ \\mathbb{V}_{\\pi}\\left[ \\theta \\right] = \\mathbb{E}_{\\pi}\\left[ h(\\theta) \\right] = \\int_{\\theta} h(\\theta) \\pi(\\theta) d\\theta, \\] where \\(h(\\theta) = \\left( \\theta - \\mathbb{E}_{\\pi}\\left[ \\theta \\mid y \\right] \\right)^2\\). When using Monte Carlo methods to estimate these integrals, we use the philosophy of approximating the target distribution \\(\\pi\\) by a sample \\(\\left\\{ \\theta^i \\right\\}_{i=1}^n\\) using \\[ \\hat{\\pi} := \\frac{1}{N} \\sum_{i=1}^N \\delta_{\\theta^i}, \\] where \\(\\delta_{\\theta^i}\\) is the delta Dirac mass at \\(\\theta^i\\). Monte Carlo estimators of integrals then follow from plugging in the approximation \\(\\hat{\\pi}\\) in place of the target distribution \\(\\pi\\). For example, the Monte Carlo estimator of the posterior expectation is \\[ \\hat{\\mathbb{E}}_{\\pi}\\left[\\theta \\right] = \\frac{1}{n} \\sum_{i=1}^n \\theta^i. \\] We may also be interested in maxima of the likelihood (the maximum likelihood estimator, MLE) or the posterior distribution (the maximum a posteriori estimator, MAP). One feature of the of the ilike package is the ability to use estimated likelihoods: for example using a sequential Monte Carlo algorithm for estimating the likelihood when using particle MCMC. A user might wonder at the validity of this approach when mixing and matching estimating likelihoods with different inference algorithms. Fortunately, this is easy to justify: details can be found in appendix ??. "],["inference-arguments.html", "2.1 Inference algorithm arguments", " 2.1 Inference algorithm arguments All inference algorithms have the following arguments in common. All users are encouraged to reed about the first two items on this page: the recipe, which is the means for providing ilike with the functions used in the inference algorithm and is required in all runs of an ilike algorithm; and the results_name, which is used in most circumstances. 2.1.1 recipe (required) Every inference algorithm requires the specification of a model, in most cases additionally some observed data and parameters required by the inference algorithm (collectively referred to in this documentation as a “recipe”). These must be specified in ilike files by the user (see section 3). The recipe argument for an inference algorithm can be provided in three possible ways: Compiled, as an ilike recipe object, through the compile function. Using a pre-compiled model is the most suitable approach where you wish to perform multiple runs of the same algorithm on the same model/data, where some parameters are changed from one run to the next. As the filename of an ilike file. This is a suitable approach when performing a single run of an algorithm on a particular model/data. Where the recipe is specified across multiple files, as a vector of filenames of ilike files. This is a useful approach when performing a single run of an algorithm, and where it is advantageous to divide the specification of the model and algorithm across multiple files (maybe when you wish to specify the model separately from the inference algorithm). 2.1.2 results_name (optional) results_name, specifies the folder where the results will be written. A new folder with this name will be created in the results_path directory. If the folder already exists, you will be prompted to check that you are ok with overwriting the contents of the folder. The default is for no results to be written to file. The results written to file depend on which algorithm is called. For MCMC, the folder contains the raw output of the chains; the IS or SMC, the weighted points. Cases in which the user may not wish to output to a file are when only, for example, evaluations of a model are required (when calling evaluate_log) or when ilike is being used to estimate a normalising constant (e.g. from IS or SMC). In these situations the function will return a numeric argument yielding the desired result. 2.1.3 results_path (optional) The name of the directory where the folder with name results_name will be written. The default is the current working directory. 2.1.4 model_parameter_list (optional) In the ilike file, some parameters can be left unspecified - instead given as p1, p2, etc. These parameters must can be provided at runtime in the model_parameter_list argument. The order of the parameters in this list must match the order in which they appear in the ilike file. 2.1.5 fixed_parameter_list (optional) In C++ functions, for example those provided for evaluating a prior or likelihood, it is possible to make use of parameters that are stored in the Parameters object passed into the function. In most cases these parameters will be those that are being inferred using, for example, an MCMC algorithm. However, it is also possible to make use of other parameters that are treated as fixed throughout the run of the inference algorithm. These must be specified at runtime as fixed parameters in the named list fixed_parameter_list. This approach is suitable when you wish to complile the recipe only once, but wish to perform multiple runs of the algorithm using different values for these fixed parameters. 2.1.6 external_packages (optional) If the ilike file contains R functions (see section 3.4) that make use of packages, their names must be provided here. Each package name must be an element in a vector of strings (e.g. external_packages = c(\"distributional\", \"mvtnorm\")). 2.1.7 julia_bin_dir (optional) If the ilike file contains Julia functions (see section 3.6), the path to the Julia binary must be provided here. 2.1.8 julia_required_libraries (optional) If the ilike file contains Julia functions (see section 3.6) that make use of Julia librry, their names must be provided here. Each package name must be an element in a vector of strings (e.g. julia_required_libraries = c(\"Distributions\", \"StatsBase\")). 2.1.9 keep_temporary_model_code (optional) If TRUE, the temporary files created during the compilation of the ilike file will be kept. This can be useful for debugging purposes. The default is FALSE. 2.1.10 seed (optional) The random number seed. If not provided, a random seed will be generated. 2.1.11 parallel (optional) This argument is available for all Monte Carlo algorithms, with the parallelisation being performed across the Monte Carlo points (or chains, in the case of MCMC). If TRUE, the inference algorithm will be run in parallel. The default is FALSE. 2.1.12 grain_size (optional) This argument is available for all Monte Carlo algorithms. The grain size for parallelisation see guidance here). The advice is to pick a large grain size (such as the default of 100000), then to try reducing the grain size (maybe halve each time) to see whether the computational time increases or decreases. A higher grain size reduces the parallelism, but requires less overhead. "],["inference-is.html", "2.2 Importance sampling", " 2.2 Importance sampling 2.2.1 Algorithm Importance sampling (IS) is used to approximate a target distribution \\(\\pi\\) through drawing \\(n\\) points from a proposal distribution \\(q\\). Each point \\(\\theta^i\\) drawn from \\(q\\) is assigned an (unnormalised) importance weight: \\[\\begin{equation} \\tilde{w}^i = \\frac{\\tilde{\\pi}(\\theta^i)}{q(\\theta^i)} \\tag{2.1} \\end{equation}\\] An approximation \\(\\hat{\\pi}\\) to the target distribution is then given by \\[ \\hat{\\pi} := \\sum_{i=1}^n w^i \\delta_{\\theta^i}, \\] where the normalised weights \\(w^i\\) are given by \\[ w^i = \\frac{\\tilde{w}^i}{\\sum_{j=1}^n \\tilde{w}^j} \\] An estimate of the normalising constant \\(Z\\) is given by \\[\\begin{equation} \\hat{Z} = \\frac{1}{n} \\sum_{i=1}^n \\tilde{w}^i. \\tag{2.2} \\end{equation}\\] For a comprehensive description see Chopin and Papaspiliopoulos (2020). The R function IS implements importance sampling in ilike. The function returns the normalising constant estimator from equation (2.2), along with writing output to the specified results_name directory. In addition to the arguments described in section 2.1, the IS function only has one additional argument: number_of_importance_points (required) This argument provides the number of importance points \\(n\\) to be drawn from the proposal distribution \\(q\\). Section 8.5.1 describes how to visualise the output of an IS algorithm after it has finished running. 2.2.2 ilike recipe requirements To run an importance sampler, we need to be able to: simulate from the proposal \\(q\\); in order to implement equation (2.1), evaluate \\(q\\) pointwise at \\(\\theta\\); in order to implement equation (2.1), evaluate the unnormalised target \\(\\tilde{\\pi}\\) pointwise at \\(\\theta\\); Points 1 and 2 require a proposal to be fully specified (simulation and evaluation) in the recipe, using the approaches in sections 6.1 and 6.2. Point 3 requires the target distribution to be fully specified, via a model (section 4). There is one exception to this rule: in the cade of Bayesian computation where the prior \\(p\\) is chosen as the proposal \\(q\\). In this case equation (2.1) simplifies to \\[ \\tilde{w}^i = \\frac{\\tilde{\\pi}(\\theta^i)}{q(\\theta^i)} = \\frac{p(\\theta^i) f(y\\mid \\theta^i) }{p(\\theta^i)} = f(y\\mid \\theta^i), \\] so that to implement IS we need only to be able to simulate from the prior \\(p\\) and evaluate the likelihood \\(f\\). In this case the recipe may be entirely specified though following the model specification in section 4, and the IS function will automatically use the prior as the proposal. In this case, only a method for simulating from the prior need be specified. References Chopin, Nicolas, and Omiros Papaspiliopoulos. 2020. An Introduction to Sequential Monte Carlo. Vol. 4. Springer. "],["inference-mcmc.html", "2.3 MCMC", " 2.3 MCMC 2.3.1 Algorithm Markov chain Monte Carlo (MCMC) uses a Markov chain whose limiting distribution is the desired target distribution \\(\\pi\\) to generate points that can be used to approximate \\(\\pi\\). In most cases in practice this boils down to implementing the Metropolis-Hastings (MH) algorithm: Metropolis-Hastings Starting with \\(\\theta^0\\) iterate for \\(i=1,2,\\dots,n\\)     Draw \\(\\theta^* \\sim q(\\cdot\\mid \\theta^{i-1})\\).     Compute    \\[\\alpha(\\theta^* \\mid \\theta^{i-1})=\\min\\left\\{1,\\frac{\\displaystyle \\tilde{\\pi}(\\theta^*) q(\\theta^{i-1}\\mid \\theta^*)}{\\tilde{\\pi}(\\theta^{i-1}) q(\\theta^*\\mid \\theta^{i-1})} \\right\\}.\\]    With probability \\(\\alpha(\\theta^* \\mid \\theta^{i-1})\\) set \\(\\theta^i=\\theta^*\\), otherwise set \\(\\theta^i=\\theta^{i-1}\\). OUTPUT: \\(\\left\\{\\theta^i\\right\\}_{i=1}^n\\) Here \\(q\\) is proposal distribution that is used at each iteration to propose a candidate point \\(\\theta^*\\) conditional on the current state of the chain \\(\\theta^{i-1}\\). The choice of proposal dramatically affects the efficiency of the algorithm. Despite the apparent simplicity of this algorithm, MCMC encompasses a wide range of different approaches. Most well-known methods, including Gibbs sampling, MALA, HMC and NUTS are special cases of MH. For a description of a number of common approaches, see Brooks et al. (2011). Most of the specification of an MCMC algorithm in ilike is done through the receipe: see section 5 for full detail. Section 8.1 then describes how to visualise the output of the MCMC algorithm after it has finished running. In this section we only describe how to run the MCMC algorithm, through calling the MCMC function. MCMC does not return anything1, but writes output to the specified results_name directory. In addition to the arguments described in section 2.1, MCMC takes the arguments: initial_values (required) A list of lists containing the initial values for the chains. The length of the outer list should be equal to the number of chains; the inner list specifies the initial values of the parameters for each chain. For example, for a single chain on a model with parameters \\(\\alpha\\) and \\(\\beta\\), if we wanted the initial values to be 1 and 2 respectively, we would use initial_values = list(list(α=1, β=2)) In the, relatively common, case where we would like to start multiple chains at the same point, one solution is to use the replicate function to repeat the initial values. For example, to start 3 chains at the same point, we would use initial_values = replicate(3, list(α=1, β=2), simplify=FALSE) number_of_chains (optional) The number of MCMC chains to run (default is 1). The number of chains needs to match the number of initial values provided. 2.3.2 ilike recipe requirements To run an MCMC algorithm the user needs to provide the following in the recipe: a method for updating the chain; the criterion for terminating the chain. A complete description is provided in section 5. References Brooks, Steve, Andrew Gelman, Galin Jones, and Xiao-Li Meng. 2011. Handbook of Markov Chain Monte Carlo. CRC press. MCMC output does not provide any useful direct estimate of \\(Z\\). So in order to be be consistent with other inference algorithms which return the an estimate of \\(Z\\).↩︎ "],["inference-smc.html", "2.4 SMC with MCMC moves", " 2.4 SMC with MCMC moves 2.4.1 Algorithm The performance of IS poor when the distance between the proposal \\(q\\) and the target \\(\\pi\\) is large. In this situation, the the points drawn from \\(q\\) may be a long way from \\(\\pi\\), and the points need to be reweighted dramatically in order to provide an approximation to \\(\\pi\\). The thing to watch out for is when the variance of the weights is very large: this likely indicates that a few of the points have a large weight, and most of the others have a very small weight. In this case, the approximation of \\(\\pi\\) will essentially be based on this small number of points that have a large weight. Sequential Monte Carlo (SMC) samplers (Del Moral, Doucet, and Jasra 2006) make use of an iterative IS-based approach to approximate a target distribution. One way of viewing SMC samplers is as an enhancement of IS that is less dependent on the choice of initial proposal. The idea is to construct a sequence of distributions between the proposal and the target, providing a “path” of \\(T\\) targets through which we move a population of weighted importance points (“particles”). We provide only a bare-bones introduction to SMC here: a comprehensive description is given by Chopin and Papaspiliopoulos (2020). The sequence of distributions is denoted by \\(\\pi_t\\) for \\(t=0:T\\), with \\(\\pi_0 = q\\) and \\(\\pi_T = \\pi\\). We use \\(\\tilde{\\pi}_t\\) to denote an unnormalised version of \\(\\pi_t\\) at iteration \\(t\\), with a normalising constant of \\(Z_t\\). We denote the position of the particles at the \\(t\\)th iteration by \\(\\left\\{ \\theta^i_t \\right\\}_{i=1}^n\\), with their weights being given by \\(\\left\\{ w^i_t \\right\\}_{i=1}^n\\). At the \\(t\\) iteration, three operations are performed: Move. Each of the particles is moved using a Markov kernel \\(K_t(\\cdot \\mid \\theta^i_{t-1})\\) to diversify the particle positions. Reweight. An IS step is used to reweight the particles such that the weighted particle population can be used to approximate the target \\(\\pi_t\\). This step consists of calculating unnormalised weights \\(\\left\\{ \\tilde{w}^i_t \\right\\}_{i=1}^n\\), then normalising them to give \\(\\left\\{ w^i_t \\right\\}_{i=1}^n\\), similarly to IS. Resample. Particles are resampled with replacement according to their weights, and their weights are all set to \\(1/n\\). Although resampled particles will include a number of duplicate particles, this step ensures that the unweighted particles (i.e. the particle positions) approximate the target \\(\\pi_t\\). An illustration of the output SMC algorithm (generated using ilike and plotted using the plot_genealogy function in ggsmc) is shown in the figure below, where the proposal (top) is a Gaussian distribution, the target (bottom) is a mixture distribution, and the size of the points represents their weights. A further illustration, on a different example, is shown in the animation below (also generated using ilike and plotted using the animate_scatter function in ggsmc). The sequence of distributions is typically chosen such that the distance between successive distributions is small, with the aim that at step \\(t\\), the particles from step \\(t-1\\) do not need dramatically reweighting (we wish the variance of the weights to be small) to approximate \\(\\pi_t\\). One sequence of distributions that is commonly chosen in practice (including in the examples above) is \\(\\pi_t \\propto q^{1-\\alpha_t} \\pi^\\alpha\\), with \\(0 = \\alpha_0 &lt; \\alpha_1 &lt; ... &lt; \\alpha_{T} = 1\\). This is commonly known as “annealing” or “tempering”. The choice of the sequence of distributions significantly affects the performance of the algorithm, as does the choice of \\(K\\), which moves the points at each iteration. In ilike, ths choice of \\(K\\) is currently restricted to an MCMC kernel, which is specified in the same way as described in 5. One use-case for ilike is that, having specifed an MCMC move, it is easy to use it in an SMC sampler as well as in a run of MCMC. Most of the specification of an SMC algorithm in ilike is done through the recipe: see section 6 for full detail. Section 8.5.1 then describes how to visualise the output of the SMC algorithm after it has finished running. In this section we only describe how to run the SMC algorithm, through calling the SMC function. SMC_with_MCMC returns the estimate of the normalising constant \\(Z\\) calculated from SMC output using \\[ \\hat{Z} = \\prod_{s=0}^t l^n_s \\quad \\mbox{where} \\quad l^n_t = \\frac{1}{n} \\sum_{i=1}^n \\tilde{w}^i_t. \\] and also writes output to the specified results_name directory. In addition to the arguments described in section 2.1, SMC_with_MCMC takes the arguments: number_of_particles (required) This argument provides the number of particles \\(n\\). smc_iterations_to_store (optional) This argument provides the number of SMC iterations to store in the output, counting backwards (inclusive) from the final iteration. The default is to store the minimal number of iterations required to perform the SMC updates (which is 2 in the current version of ilike). If the user wishes to examine the entire SMC history, they should choose a number that is equal to or larger than \\(T+1\\). If only points from the final target as required, and memory requirements are a concern due to the output only being written to file at the end of the run (see below), then the default values is recommended. write_to_file_at_each_iteration (optional) This boolean argument allows the user to choose if the output will be written to the file at the end of every iteration (use TRUE, which is also the default), or if the output of each SMC iteration will be written to file between iterations (use FALSE). 2.4.2 ilike recipe requirements To run an SMC algorithm with MCMC moves the user needs to provide the requirements described in both those described in 2.2.2 (for IS) and in 2.3.2 (for MCMC). As in IS, in the case of Bayesian computation, if the proposal is not specified, the prior will be used by default. There are no other essential requirements to ensure that an SMC algorithm will run. However, if no sequence of distributions is set, the algorithm will default to performing IS. Thus the user should specify a sequence of distributions as described in section 6.3. A complete description is provided in section 6, including options to adaptively choose the sequence of distributions and to resample adaptively. References Chopin, Nicolas, and Omiros Papaspiliopoulos. 2020. An Introduction to Sequential Monte Carlo. Vol. 4. Springer. Del Moral, Pierre, Arnaud Doucet, and Ajay Jasra. 2006. “Sequential Monte Carlo Samplers.” Journal of the Royal Statistical Society Series B: Statistical Methodology 68 (3): 411–36. "],["inference-pf.html", "2.5 Particle filters", " 2.5 Particle filters Particle filters (PFs) are a particular type of SMC algorithm (as in the previous section, section 2.4), where the sequence of distributions is determined by a state-space model (SSM). An SSM describes the evolution of an indirectly observed latent “state” variable over time (from 0 to \\(T\\)). We denote the state at time \\(t\\) as \\(x_t\\) and the observation at time \\(t\\) as \\(y_t\\). A Markov assumption is made on the state, so that the distribution of \\(x_t\\) depends only on \\(x_{t-1}\\). Along with the prior distribution at time 0, denoted \\(p\\), the distribution of \\(x_t \\mid x_{t-1}\\), known as the transition/dynamic model, is sufficient to describe the distribution on the latent state. We denote this distribution using \\(p_t\\). A further conditional independence assumption is made that \\(y_t\\) is conditionally independent of all other variables in the system given \\(x_t\\). The distribution of \\(y_t\\) given \\(x_t\\), which we denote using \\(f_t\\), is known as the measurement/observation model. Together this provides a joint distribution over variables \\(x_{0:T}\\) and \\(y_{0:T}\\): \\[ p\\left( x_0 \\right) \\prod_{t=1}^T p_t\\left(x_t \\mid x_{t-1} \\right) \\prod_{t=0}^T f_t \\left( y_t \\mid x_t \\right). \\] SSMs are also used in sections 2.7 and @(inference-kf). We describe how to specify an SSM in ilike in chapter 7. PFs are focused on the inference goal of filtering: i.e. given measurements up to time \\(t\\), inferring \\(\\pi_t\\left( x_t \\mid y_{0:t} \\right)\\). As a by-product they also provide an estimator of the normalising constant \\(Z_t = p\\left( y_{0:t} \\right)\\). A PF iteratively approximates \\(\\pi_t\\left( x_t \\mid y_{0:t} \\right)\\) using a population of particles \\(\\left\\{ x^i_t \\right\\}_{i=1}^n\\), with weights \\(\\left\\{ w^i_t \\right\\}_{i=1}^n\\) through an SMC algorithm that use the following steps at iteration \\(t\\) (on receipt of measurement \\(y_t\\)): Move. Each of the particles is moved using a Markov kernel \\(q_t(\\cdot \\mid x^i_{t-1})\\), which we call a transition proposal, to move the points from their positions at iteration \\(t-1\\) to new positions at time \\(t\\). Reweight. An IS step is used to reweight the particles such that the weighted particle population can be used to approximate the target \\(\\pi_t\\). This step consists of calculating unnormalised weights \\(\\left\\{ \\tilde{w}^i_t \\right\\}_{i=1}^n\\), then normalising them to give \\(\\left\\{ w^i_t \\right\\}_{i=1}^n\\), similarly to IS. Resample. Particles are resampled with replacement according to their weights, and their weights are all set to \\(1/n\\). Although resampled particles will include a number of duplicate particles, this step ensures that the unweighted particles (i.e. the particle positions) approximate the target \\(\\pi_t\\). Most of the specification of an PF algorithm in ilike is done through the recipe (see section 2.5.1). The PF function is used to run a PF, which returns the estimate of the normalising constant \\(Z_T\\) (for \\(T\\) measurements) calculated from PF output using \\[ \\hat{Z_T} = \\prod_{s=0}^t l^n_s \\quad \\mbox{where} \\quad l^n_t = \\frac{1}{n} \\sum_{i=1}^n \\tilde{w}^i_t. \\] and also writes output to the specified results_name directory. In addition to the arguments described in section 2.1, PF takes the arguments: number_of_particles (required) This argument provides the number of particles \\(n\\). smc_iterations_to_store (optional) This argument provides the number of SMC iterations to store in the output, counting backwards (inclusive) from the final iteration. The default is to store the minimal number of iterations required to perform the SMC updates (which is 2 in the current version of ilike). If the user wishes to examine the entire SMC history, they should choose a number that is equal to or larger than \\(T+1\\). If only points from the final target as required, and memory requirements are a concern due to the output only being written to file at the end of the run (see below), then the default values is recommended. write_to_file_at_each_iteration (optional) This boolean argument allows the user to choose if the output will be written to the file at the end of every iteration (use TRUE, which is also the default), or if the output of each SMC iteration will be written to file between iterations (use FALSE). As for an SMC sampler, section 8.5.1 then describes how to visualise the output of the PF after it has finished running. 2.5.1 ilike recipe requirements To use the function PF, the recipe must specify: An IS proposal \\(q_0\\), which is used to generate points at the 0th iteration of the PF. The specification would follow that described in section 6.1 or ??. As in section (requirements-is), a method for simulating from and evaluating must both be specified. If no proposal is specified, the prior specified in the SSM (see the next point) is used as the initial proposal, and only a method to simulate from the prior is required (similarly to section (requirements-is)). An SSM, as described in section 7. A transition proposal \\(q_t\\), which is also described in section 7. If no transition proposal is supplied, the transition model will be used as the transition proposal. In this case, only an approach to simulating from the transition model need be supplied when specifying the model, since the transition model need not be evaluated in the PF weight update (via a similar argument to that seen in section (requirements-is)). "],["inference-kf.html", "2.6 Kalman filters", " 2.6 Kalman filters This section relies on ideas (state-space models, filtering) introduced in section 2.5 on particle filters. Kalman filters (KFs) provide an exact solution to the filtering problem for a SSM in the case where the transition model \\(p_t(\\cdot \\mid x_{t-1})\\) and measurement model \\(f_t(\\cdot \\mid x_{t})\\) are both (multivariate) Gaussian and where the mean depends linearly on, for the transition model \\(x_{t-1}\\) (equation (??)), and for the measurement model \\(x_{t}\\) (equation (??)). In this case the filtering distribution at each iteration \\(t\\) is also Gaussian and is fully described using a mean \\(\\mu_t\\) and covariance \\(\\Sigma_t\\). The update from the filtering distribution at time \\(t-1\\) to time \\(t\\) can be described via matrix operations on the mean and covariance. ilike contains a straightforward implementation of the KF2. The KF function is used to run a KF, which return the (exact) normalising constant \\(Z_T\\) (for \\(T\\) measurements) calculated from KF output. In addition to the arguments described in section 2.1, KF takes the arguments: kf_iterations_to_store (optional) This argument provides the number of SMC iterations to store in the output, counting backwards (inclusive) from the final iteration. To be consistent with the PF, the default is to output the mean and covariance from the last 2 iterations. If the user wishes to examine the entire KF history, they should choose a number that is equal to or larger than \\(T+1\\). If only the mean and covariance from the final target as required, and memory requirements are a concern due to the output only being written to file at the end of the run (see below), then the default values is recommended. write_to_file_at_each_iteration (optional) This boolean argument allows the user to choose if the output will be written to the file at the end of every iteration (use TRUE, which is also the default), or if the output of each SMC iteration will be written to file between iterations (use FALSE). 2.6.1 ilike recipe requirements The KF requires only the specification of a linear-Gaussian SSM, following section 7. The transition model must be specified using the method from section 7.2, and the measurement model must be specified using the method from section 4.5. This implementation is currently unlikely to be as robust as those found in some other packages. THus far it has only been tested on models where the standard implementation is well-behaved.↩︎ "],["inference-enkf.html", "2.7 Ensemble Kalman filters", " 2.7 Ensemble Kalman filters This section relies on ideas (state-space models, filtering) introduced in section 2.5 on particle filters. Ensemble-Kalman filters provide an alternative to particle filters for the filtering problem in the case of non-linear/Gaussian measurement models. That is, the conditional distribution \\(f_t\\) is Gaussian, where the mean is given by a possibly non-linear function of \\(x_t\\) (equation (??)). The ensemble-Kalman filter (EnKF) is a Monte Carlo approximation of the Kalman filter. An ensemble \\(\\left\\{ x^i_t \\right\\}\\) is used to approximate the filtering distribution \\(\\pi_{t}\\) at iteration \\(t\\). The ensemble is updated from time \\(t-1\\) to \\(t\\) through a sequence of operations that, for a linear/Gaussian SSM, would result in the sample mean and covariance of the ensemble being estimators of the true mean and covariance of the filtering distribution. This is performed in two steps: Prediction where the ensemble is simulated from the transition model \\(x^i_t \\sim p_t(\\cdot \\mid x^i_{t-1})\\); Update where each member of the ensemble is moved such that the sample mean and variance of the updated ensemble estimate the mean and variance of the true filtering distribution. Whilst the update is only exact in the linear/Gaussian case, the same sequence of operations can be used outside of this case to provide an approximation to the filtering distribution. Katzfuss, Stroud, and Wikle (2016) contains a useful review from the statistical perspective. Most of the specification of an EnKF algorithm in ilike is done through the recipe (see section 2.5.1). The EnKF function is used to run an EnKF, which returns the estimate of the normalising constant \\(Z_T\\) (for \\(T\\) measurements) calculated from PF output using the direct (biased) estimator described in Drovandi et al. (2022), and also writes output to the specified results_name directory. In addition to the arguments described in section 2.1, EnKF takes the arguments: number_of_ensemble_members (required) This argument provides the number of ensemble members \\(n\\). enkf_iterations_to_store (optional) This argument provides the number of EnKF iterations to store in the output, counting backwards (inclusive) from the final iteration. The default is to store the minimal number of iterations required to perform the EnKF updates (which is 2 in the current version of ilike). If the user wishes to examine the entire EnKF history, they should choose a number that is equal to or larger than \\(T+1\\). If only points from the final target as required, and memory requirements are a concern due to the output only being written to file at the end of the run (see below), then the default values is recommended. write_to_file_at_each_iteration (optional) This boolean argument allows the user to choose if the output will be written to the file at the end of every iteration (use TRUE, which is also the default), or if the output of each EnKF iteration will be written to file between iterations (use FALSE). As for a PF, section 8.3 then describes how to visualise the output of the PF after it has finished running. 2.7.1 ilike recipe requirements The EnKF requires only the specification of a linear-Gaussian SSM, following section 7. The transition model must be specified using any approach, but the measurement model must be specified using the method from either section 4.5 or section 4.6. References Drovandi, Christopher, Richard G Everitt, Andrew Golightly, and Dennis Prangle. 2022. “Ensemble MCMC: Accelerating Pseudo-Marginal MCMC for State Space Models Using the Ensemble Kalman Filter.” Bayesian Analysis 17 (1): 223–60. Katzfuss, Matthias, Jonathan R Stroud, and Christopher K Wikle. 2016. “Understanding the Ensemble Kalman Filter.” The American Statistician 70 (4): 350–57. "],["inference-eval.html", "2.8 Evaluate", " 2.8 Evaluate 2.8.1 Algorithm Rather than running an inference algorithm, this function provides the ability to pointwise evaluate (the log of) a model specified in a recipe. Suppose the a model \\(\\tilde{\\pi}(\\theta) = p(\\theta) f(y \\mid \\theta)\\) is specified in a recipe, alongside observed data \\(y\\). This function describes how to evaluate \\(\\log \\tilde{\\pi}\\) at a \\(\\theta\\) provided by the user. We anticipate that this function will be of most use for debugging a model before using it in an inference algorithm. The R function evaluate_log implements this functionality. In addition to the arguments described in section 2.1, the evaluate_log function has two additional arguments: parameters (required) This argument is a named list that provides the values of the parameters at which to evaluated the model; index (optional) This argument is a vector that provides the indices of the factors (i.e. priors or likelihoods) of the model to evaluate, starting at 1 for the first factor provided in the recipe. The default is to evaluate all factors. 2.8.2 ilike recipe requirements To run the evaluate function in the receipe we require either: (with observed data) functions that are sufficient to evaluate the priors and likelihoods used as factors in the model, plus observed data to allow the likelihoods to be evaluated; or: (without observed data) functions that are sufficient to evaluate the priors used as factors in the model, with no likelihoods specified. "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
